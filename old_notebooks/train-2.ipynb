{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcd9e47b-ac86-47f8-8f40-3d7ab357ce17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, torch, torch.nn as nn\n",
    "from datasets import Dataset, DatasetDict\n",
    "from collections import defaultdict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoConfig,\n",
    "    Trainer, TrainingArguments,\n",
    "    DataCollatorForTokenClassification,\n",
    "    EarlyStoppingCallback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe4fd86-f324-441d-bcf0-941a88d0897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov  3 21:49:24 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:8B:00.0 Off |                    0 |\n",
      "| N/A   42C    P0             82W /  400W |       1MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2905a12-33d2-4c45-8984-4d55f01e0e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1-a  Read tagged train ###\n",
    "tagged = pd.read_csv(\n",
    "    \"../data/Tagged_Titles_Train.tsv\",\n",
    "    sep=\"\\t\", keep_default_na=False, na_values=None\n",
    ")\n",
    "\n",
    "### 1-b  Per-category allow-set ###\n",
    "allow = (\n",
    "    tagged.groupby(\"Category\")[\"Tag\"]\n",
    "          .apply(lambda s: set(s.unique()) - {\"\"})\n",
    "          .to_dict()\n",
    ")\n",
    "\n",
    "### 1-c  Union BIO label list ###\n",
    "BASE = set(t for t in tagged[\"Tag\"].unique() if t and t != \"O\")\n",
    "label_list = [\"O\"] + sorted(\n",
    "    f\"{p}-{t}\" for t in BASE for p in (\"B\",\"I\")\n",
    ")\n",
    "label2id = {l:i for i,l in enumerate(label_list)}\n",
    "id2label = {i:l for l,i in label2id.items()}\n",
    "\n",
    "### 1-d  Category→mask tensor (bool[num_labels]) ###\n",
    "allow_mask = {}\n",
    "for cat in [1,2]:\n",
    "    ok = {\"O\"}\n",
    "    for t in allow[cat]:\n",
    "        ok.add(f\"B-{t}\"); ok.add(f\"I-{t}\")\n",
    "    allow_mask[cat] = torch.tensor([l in ok for l in label_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd20b7b1-9096-46f9-a054-1b5fdf131eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'Category'],\n",
       "        num_rows: 4250\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'Category'],\n",
       "        num_rows: 750\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rows_to_examples(df):\n",
    "    \"\"\"\n",
    "    Correctly handle multi-token entities and separate consecutive same-tag entities.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    \n",
    "    for record_num, group in df.groupby(\"Record Number\"):\n",
    "        group = group.sort_index()\n",
    "        \n",
    "        tokens = []\n",
    "        bio_tags = []\n",
    "        \n",
    "        prev_tag = None\n",
    "        entity_started = False\n",
    "        \n",
    "        for idx, row in group.iterrows():\n",
    "            token = row[\"Token\"]\n",
    "            tag = row[\"Tag\"]\n",
    "            \n",
    "            # Handle empty tags (continuation of previous entity)\n",
    "            if pd.isna(tag) or tag == \"\":\n",
    "                if prev_tag and prev_tag != \"O\":\n",
    "                    # Continue previous entity\n",
    "                    tokens.append(token)\n",
    "                    bio_tags.append(f\"I-{prev_tag}\")\n",
    "                else:\n",
    "                    # Empty tag but no previous entity - treat as O\n",
    "                    tokens.append(token)\n",
    "                    bio_tags.append(\"O\")\n",
    "                    prev_tag = \"O\"\n",
    "                continue\n",
    "            \n",
    "            # Non-empty tag\n",
    "            tokens.append(token)\n",
    "            \n",
    "            if tag == \"O\":\n",
    "                bio_tags.append(\"O\")\n",
    "                prev_tag = \"O\"\n",
    "                entity_started = False\n",
    "            else:\n",
    "                # Always use B- for new non-empty tag (each is a separate entity)\n",
    "                bio_tags.append(f\"B-{tag}\")\n",
    "                prev_tag = tag\n",
    "                entity_started = True\n",
    "        \n",
    "        records.append({\n",
    "            \"tokens\": tokens,\n",
    "            \"ner_tags\": [label2id[b] for b in bio_tags],\n",
    "            \"Category\": int(group[\"Category\"].iloc[0])\n",
    "        })\n",
    "    \n",
    "    return records\n",
    "\n",
    "hf_ds = Dataset.from_list(rows_to_examples(tagged))\n",
    "splits = hf_ds.train_test_split(test_size=0.15, seed=42)\n",
    "splits = DatasetDict({\n",
    "    \"train\": splits[\"train\"],\n",
    "    \"validation\": splits[\"test\"]\n",
    "})\n",
    "splits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0038893-505d-4f44-9497-1a56a2c752ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = \"../models/deberta-improved-weak-ner-mk-2\"\n",
    "tok = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "696c7982-b50f-4fcf-bd9e-ad4eb85a5ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6669cb7a09a04c23b08382e715fabc10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tok_fn(batch):\n",
    "    enc = tok(\n",
    "        batch[\"tokens\"],\n",
    "        is_split_into_words=True,\n",
    "        padding=False,     # fixes input_ids length\n",
    "        # padding=\"longest\",\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    # ---- build label matrix *already padded* ----\n",
    "    all_labels = []\n",
    "    for i, word_ids in enumerate(enc.word_ids(batch_index=i)\n",
    "                                 for i in range(len(enc[\"input_ids\"]))):\n",
    "        gold = batch[\"ner_tags\"][i]\n",
    "        seq  = []\n",
    "        prev = None\n",
    "        for wid in word_ids:\n",
    "            if wid is None:               # CLS / SEP / PAD\n",
    "                seq.append(-100)\n",
    "            elif wid != prev:             # first sub-word\n",
    "                seq.append(gold[wid])\n",
    "                prev = wid\n",
    "            else:                         # non-first sub-word\n",
    "                seq.append(-100)\n",
    "        all_labels.append(seq)            # len(seq) == len(input_ids[i])\n",
    "    enc[\"labels\"]       = all_labels\n",
    "    enc[\"word_ids\"]     = [enc.word_ids(i) for i in range(len(enc[\"input_ids\"]))]\n",
    "    enc[\"category_id\"]  = batch[\"Category\"]\n",
    "    return enc\n",
    "\n",
    "\n",
    "# tokenised = splits.map(tok_fn, batched=True, remove_columns=[\"tokens\",\"ner_tags\",\"Category\"])\n",
    "tokenised = hf_ds.map(tok_fn, batched=True, remove_columns=[\"tokens\",\"ner_tags\",\"Category\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b826122e-1865-455c-9065-21bc6423eafe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, PreTrainedModel, AutoConfig\n",
    "from torchcrf import CRF\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class CatAwareCRF(PreTrainedModel):\n",
    "    config_class = AutoConfig\n",
    "    \n",
    "    def __init__(self, config, num_labels=None, allow_mask=None, \n",
    "                 base_model_name=None, use_dapt=False, **kwargs):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.allow_mask = {k: v.bool() for k, v in allow_mask.items()} if allow_mask else {}\n",
    "        \n",
    "        # IMPROVED: Load DAPT encoder if specified\n",
    "        if use_dapt and base_model_name:\n",
    "            print(f\"Loading DAPT encoder from {base_model_name}\")\n",
    "            self.encoder = AutoModel.from_pretrained(\n",
    "                base_model_name, \n",
    "            )\n",
    "        elif base_model_name and not hasattr(config, \"_name_or_path\"):\n",
    "            self.encoder = AutoModel.from_pretrained(\n",
    "                base_model_name, \n",
    "            )\n",
    "        else:\n",
    "            self.encoder = AutoModel.from_config(config)\n",
    "        \n",
    "        # Task-specific layers\n",
    "        self.cat_embed = nn.Embedding(3, 64)  # INCREASED from 32\n",
    "        self.dropout = nn.Dropout(0.2)  # INCREASED from config default\n",
    "        self.proj = nn.Linear(config.hidden_size + 64, num_labels)\n",
    "        self.crf = CRF(num_labels, batch_first=True)\n",
    "        \n",
    "        # Initialize new layers only (not encoder)\n",
    "        self._init_task_layers()\n",
    "    \n",
    "    def _init_task_layers(self):\n",
    "        \"\"\"Initialize only task-specific layers, not encoder.\"\"\"\n",
    "        nn.init.normal_(self.cat_embed.weight, std=0.02)\n",
    "        nn.init.normal_(self.proj.weight, std=0.02)\n",
    "        nn.init.zeros_(self.proj.bias)\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, \n",
    "                labels=None, category_id=None, **ignored):\n",
    "        h = self.encoder(input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "        \n",
    "        # Category embedding\n",
    "        cat = self.cat_embed(category_id).unsqueeze(1).expand(-1, h.size(1), -1)\n",
    "        combined = torch.cat([h, cat], dim=-1)\n",
    "        \n",
    "        # Projection\n",
    "        logits = self.proj(self.dropout(combined))\n",
    "        \n",
    "        # IMPROVED: Category-aware masking with proper numerical stability\n",
    "        for c in (1, 2):\n",
    "            bad = ~self.allow_mask[c].to(logits.device)\n",
    "            idx = (category_id == c).nonzero(as_tuple=True)[0]\n",
    "            if len(idx):\n",
    "                # Use -1e10 instead of -1e4 for better masking\n",
    "                logits[idx][:, :, bad] = -1e10\n",
    "        \n",
    "        if labels is not None:\n",
    "            mask = attention_mask.bool()\n",
    "            safe_labels = labels.clone()\n",
    "            safe_labels[labels == -100] = 0\n",
    "            \n",
    "            # Token-mean reduction for stability\n",
    "            log_lik = self.crf(logits, safe_labels, mask=mask, reduction=\"token_mean\")\n",
    "            return {\"loss\": -log_lik, \"logits\": logits}\n",
    "        else:\n",
    "            paths = self.crf.decode(logits, mask=attention_mask.bool())\n",
    "            max_len = logits.size(1)\n",
    "            out = torch.full((len(paths), max_len), -100, \n",
    "                           dtype=torch.long, device=logits.device)\n",
    "            for i, seq in enumerate(paths):\n",
    "                out[i, :len(seq)] = torch.tensor(seq, device=logits.device)\n",
    "            return {\"logits\": out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "febc414a-698e-4a2a-94cc-89480df7bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, PreTrainedModel, AutoConfig\n",
    "from torchcrf import CRF\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CatAwareCRF(PreTrainedModel):\n",
    "    config_class = AutoConfig\n",
    "    \n",
    "    def __init__(self, config, num_labels=None, allow_mask=None, \n",
    "                 base_model_name=None, use_dapt=False, label_smoothing=0.02, **kwargs):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.allow_mask = {k: v.bool() for k, v in allow_mask.items()} if allow_mask else {}\n",
    "        self.label_smoothing = label_smoothing\n",
    "        \n",
    "        # IMPROVED: Load DAPT encoder if specified\n",
    "        if use_dapt and base_model_name:\n",
    "            print(f\"Loading DAPT encoder from {base_model_name}\")\n",
    "            self.encoder = AutoModel.from_pretrained(\n",
    "                base_model_name, \n",
    "            )\n",
    "        elif base_model_name and not hasattr(config, \"_name_or_path\"):\n",
    "            self.encoder = AutoModel.from_pretrained(\n",
    "                base_model_name, \n",
    "            )\n",
    "        else:\n",
    "            self.encoder = AutoModel.from_config(config)\n",
    "        \n",
    "        # Task-specific layers\n",
    "        self.cat_embed = nn.Embedding(3, 64)  # INCREASED from 32\n",
    "        self.dropout = nn.Dropout(0.2)  # INCREASED from config default\n",
    "        self.proj = nn.Linear(config.hidden_size + 64, num_labels)\n",
    "        self.crf = CRF(num_labels, batch_first=True)\n",
    "        \n",
    "        # Initialize new layers only (not encoder)\n",
    "        self._init_task_layers()\n",
    "    \n",
    "    def _init_task_layers(self):\n",
    "        \"\"\"Initialize only task-specific layers, not encoder.\"\"\"\n",
    "        nn.init.normal_(self.cat_embed.weight, std=0.02)\n",
    "        nn.init.normal_(self.proj.weight, std=0.02)\n",
    "        nn.init.zeros_(self.proj.bias)\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, \n",
    "                labels=None, category_id=None, **ignored):\n",
    "        h = self.encoder(input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "        \n",
    "        # Category embedding\n",
    "        cat = self.cat_embed(category_id).unsqueeze(1).expand(-1, h.size(1), -1)\n",
    "        combined = torch.cat([h, cat], dim=-1)\n",
    "        \n",
    "        # Projection\n",
    "        logits = self.proj(self.dropout(combined))\n",
    "        \n",
    "        # IMPROVED: Category-aware masking with proper numerical stability\n",
    "        for c in (1, 2):\n",
    "            bad = ~self.allow_mask[c].to(logits.device)\n",
    "            idx = (category_id == c).nonzero(as_tuple=True)[0]\n",
    "            if len(idx):\n",
    "                # Use -1e10 instead of -1e4 for better masking\n",
    "                logits[idx][:, :, bad] = -1e10\n",
    "        \n",
    "        if labels is not None:\n",
    "            mask = attention_mask.bool()\n",
    "            safe_labels = labels.clone()\n",
    "            safe_labels[labels == -100] = 0\n",
    "            \n",
    "            # Add label smoothing\n",
    "            if self.label_smoothing > 0:\n",
    "                # Smooth the labels before CRF\n",
    "                num_labels = logits.size(-1)\n",
    "                smooth_labels = safe_labels.float()\n",
    "                # CRF expects hard labels, so apply smoothing to loss\n",
    "                log_lik = self.crf(logits, safe_labels, mask=mask, reduction=\"token_mean\")\n",
    "                \n",
    "                # Add regularization term\n",
    "                uniform_dist = torch.full_like(logits, 1.0 / num_labels)\n",
    "                kl_loss = F.kl_div(\n",
    "                    F.log_softmax(logits, dim=-1),\n",
    "                    uniform_dist,\n",
    "                    reduction='batchmean'\n",
    "                )\n",
    "                loss = -log_lik + self.label_smoothing * kl_loss\n",
    "            else:\n",
    "                log_lik = self.crf(logits, safe_labels, mask=mask, reduction=\"token_mean\")\n",
    "                loss = -log_lik\n",
    "            \n",
    "            return {\"loss\": loss, \"logits\": logits}\n",
    "        else:\n",
    "            paths = self.crf.decode(logits, mask=attention_mask.bool())\n",
    "            max_len = logits.size(1)\n",
    "            out = torch.full((len(paths), max_len), -100, \n",
    "                           dtype=torch.long, device=logits.device)\n",
    "            for i, seq in enumerate(paths):\n",
    "                out[i, :len(seq)] = torch.tensor(seq, device=logits.device)\n",
    "            return {\"logits\": out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d7db35-6be6-43ba-b03c-4976382812f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b5196d-242c-4add-9792-3dfe67ac318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_dapt = True\n",
    "\n",
    "cfg = AutoConfig.from_pretrained(\n",
    "    base_model,\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "model = CatAwareCRF(\n",
    "    cfg, \n",
    "    num_labels=len(label_list), \n",
    "    allow_mask=allow_mask, \n",
    "    base_model_name=base_model,\n",
    "    use_dapt=use_dapt\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a85babc-d515-4de8-92f7-db4570beb467",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column validation not in the dataset. Current columns in the dataset: ['input_ids', 'token_type_ids', 'attention_mask', 'labels', 'word_ids', 'category_id']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     56\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m metric_weighted_fbeta\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m compute_metrics_ = make_weighted_fbeta(\u001b[43mtokenised\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalidation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:2777\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   2775\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[32m   2776\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2777\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:2761\u001b[39m, in \u001b[36mDataset._getitem\u001b[39m\u001b[34m(self, key, **kwargs)\u001b[39m\n\u001b[32m   2759\u001b[39m format_kwargs = format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m   2760\u001b[39m formatter = get_formatter(format_type, features=\u001b[38;5;28mself\u001b[39m._info.features, **format_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m2761\u001b[39m pa_subtable = \u001b[43mquery_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2762\u001b[39m formatted_output = format_table(\n\u001b[32m   2763\u001b[39m     pa_subtable, key, formatter=formatter, format_columns=format_columns, output_all_columns=output_all_columns\n\u001b[32m   2764\u001b[39m )\n\u001b[32m   2765\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/datasets/formatting/formatting.py:604\u001b[39m, in \u001b[36mquery_table\u001b[39m\u001b[34m(table, key, indices)\u001b[39m\n\u001b[32m    602\u001b[39m         _raise_bad_key_type(key)\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[43m_check_valid_column_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    606\u001b[39m     size = indices.num_rows \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m table.num_rows\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/datasets/formatting/formatting.py:541\u001b[39m, in \u001b[36m_check_valid_column_key\u001b[39m\u001b[34m(key, columns)\u001b[39m\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_valid_column_key\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m, columns: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    540\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in the dataset. Current columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"Column validation not in the dataset. Current columns in the dataset: ['input_ids', 'token_type_ids', 'attention_mask', 'labels', 'word_ids', 'category_id']\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_weighted_fbeta(eval_ds):\n",
    "    cats = np.array(eval_ds[\"category_id\"])        # 1-D, same order as eval_ds\n",
    "    wids = eval_ds[\"word_ids\"]                     # list-of-lists, same order\n",
    "    β, β2 = 0.2, 0.2 ** 2\n",
    "\n",
    "    def metric_weighted_fbeta(p):                  # ← give this to Trainer\n",
    "        # ── 1. get label-ids from predictions ──────────────────────────\n",
    "        if p.predictions.ndim == 3:                # logits  [B,L,C]\n",
    "            preds = p.predictions.argmax(-1)\n",
    "        else:                                      # already [B,L] ids (CRF decode)\n",
    "            preds = p.predictions\n",
    "        golds = p.label_ids\n",
    "\n",
    "        # ── 2. build token-level maps ──────────────────────────────────\n",
    "        gold_map, pred_map = {}, {}                # (cat, aspect) → {(seq,tok)}\n",
    "\n",
    "        for i, (plab, glab, wid_list) in enumerate(zip(preds, golds, wids)):\n",
    "            cat = int(cats[i])\n",
    "            for tok_idx, pid, gid in zip(wid_list, plab, glab):\n",
    "                if tok_idx is None or gid == -100:\n",
    "                    continue                       # skip pads / second sub-words\n",
    "\n",
    "                # gold\n",
    "                g_lbl = id2label[gid]\n",
    "                if g_lbl != \"O\":\n",
    "                    asp = g_lbl.split(\"-\", 1)[-1]\n",
    "                    gold_map.setdefault((cat, asp), set()).add((i, tok_idx))\n",
    "\n",
    "                # pred\n",
    "                p_lbl = id2label[pid]\n",
    "                if p_lbl != \"O\":\n",
    "                    asp = p_lbl.split(\"-\", 1)[-1]\n",
    "                    pred_map.setdefault((cat, asp), set()).add((i, tok_idx))\n",
    "\n",
    "        # ── 3. weighted Fβ per category ────────────────────────────────\n",
    "        out = {}\n",
    "        for cat in (1, 2):\n",
    "            f_cat = 0.0\n",
    "            aspects = {a for (c, a) in gold_map if c == cat}\n",
    "            total_gold_tok = sum(len(gold_map[(cat, a)]) for a in aspects)\n",
    "\n",
    "            for asp in aspects:\n",
    "                g_set = gold_map.get((cat, asp), set())\n",
    "                p_set = pred_map.get((cat, asp), set())\n",
    "                tp = len(g_set & p_set)\n",
    "                prec = tp / len(p_set) if p_set else 0.0\n",
    "                rec  = tp / len(g_set) if g_set else 0.0\n",
    "                fβ = (1 + β2) * prec * rec / (β2 * prec + rec) if (prec + rec) else 0.0\n",
    "                f_cat += len(g_set) * fβ                      # weight by true count\n",
    "\n",
    "            out[f\"Fbeta_cat{cat}\"] = f_cat / total_gold_tok if total_gold_tok else 0.0\n",
    "\n",
    "        out[\"final_score\"] = 0.5 * (out[\"Fbeta_cat1\"] + out[\"Fbeta_cat2\"])\n",
    "        return out\n",
    "\n",
    "    return metric_weighted_fbeta\n",
    "\n",
    "compute_metrics_ = make_weighted_fbeta(tokenised[\"validation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d34e6b44-06d5-4be1-87fb-394905589e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_collator(features):\n",
    "    # Determine max sequence length dynamically for this batch\n",
    "    max_len = max(len(f[\"input_ids\"]) for f in features)\n",
    "\n",
    "    # pad function\n",
    "    def pad_to_max(seq, pad_value=0):\n",
    "        return seq + [pad_value] * (max_len - len(seq))\n",
    "\n",
    "    # Build tensor fields\n",
    "    input_ids = torch.tensor([pad_to_max(f[\"input_ids\"], pad_value=tok.pad_token_id) for f in features], dtype=torch.long)\n",
    "    attention_mask = torch.tensor([pad_to_max(f[\"attention_mask\"], pad_value=0) for f in features], dtype=torch.long)\n",
    "\n",
    "    # For labels, use -100 as ignore index pad\n",
    "    labels = torch.tensor([pad_to_max(f[\"labels\"], pad_value=-100) for f in features], dtype=torch.long)\n",
    "    \n",
    "    category_id = torch.tensor([f[\"category_id\"] for f in features], dtype=torch.long)\n",
    "\n",
    "    batch = {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "        \"category_id\": category_id,\n",
    "    }\n",
    "\n",
    "    # word_ids (for metrics)\n",
    "    if \"word_ids\" in features[0]:\n",
    "        batch[\"word_ids\"] = [f[\"word_ids\"] for f in features]\n",
    "\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "740dc933-9a9a-40ad-84b4-ff29fb31110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"deberta-improved-weak-ner-finetuned\",\n",
    "    # BATCH SIZE: Optimized for CRF memory requirements\n",
    "    per_device_train_batch_size=64,      # REDUCED from 128\n",
    "    per_device_eval_batch_size=48,       # REDUCED from 64\n",
    "    gradient_accumulation_steps=4,       # Effective = 128\n",
    "    \n",
    "    # LEARNING RATE: Lower after DAPT\n",
    "    learning_rate=3e-6,                  # REDUCED from 2e-5 (critical!)\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.2,                   # INCREASED warmup\n",
    "    max_grad_norm=1.0,\n",
    "    \n",
    "    # EPOCHS: Reduced to prevent overfitting\n",
    "    num_train_epochs=20,                 # REDUCED from 60\n",
    "    \n",
    "    # OPTIMIZATION\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    lr_scheduler_type=\"cosine\",  # CHANGED\n",
    "    \n",
    "    # MIXED PRECISION: BF16 for CRF stability\n",
    "    bf16=True,                           # CHANGED from FP16\n",
    "    fp16=False,\n",
    "    \n",
    "    # EVALUATION & SAVING\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"final_score\",\n",
    "    greater_is_better=True,\n",
    "    \n",
    "    # LOGGING\n",
    "    logging_steps=50,\n",
    "    logging_first_step=True,\n",
    "    \n",
    "    # EFFICIENCY\n",
    "    dataloader_num_workers=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    gradient_checkpointing=False,\n",
    "    \n",
    "    # REPRODUCIBILITY\n",
    "    seed=42,\n",
    "    data_seed=42,\n",
    "    \n",
    "    # MISC\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# num_training_steps = len(tokenised[\"train\"]) // args.per_device_train_batch_size * args.num_train_epochs\n",
    "# lr_scheduler = get_scheduler(\"cosine\", optimizer=optimizer, num_warmup_steps=int(0.1*num_training_steps),\n",
    "#                              num_training_steps=num_training_steps)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenised[\"train\"],\n",
    "    eval_dataset=tokenised[\"validation\"],\n",
    "    data_collator=new_collator,\n",
    "    processing_class=tok,\n",
    "    compute_metrics=compute_metrics_,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(\n",
    "            early_stopping_patience=3,      # Stop after 3 epochs no improvement\n",
    "            early_stopping_threshold=0.001   # 0.1% threshold\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ba510d5-8a6f-4716-8b70-007f27691ad9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='272' max='340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [272/340 10:33 < 02:39, 0.43 it/s, Epoch 16/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Fbeta Cat1</th>\n",
       "      <th>Fbeta Cat2</th>\n",
       "      <th>Final Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.673300</td>\n",
       "      <td>1.210911</td>\n",
       "      <td>0.694115</td>\n",
       "      <td>0.546409</td>\n",
       "      <td>0.620262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.673300</td>\n",
       "      <td>1.017413</td>\n",
       "      <td>0.777951</td>\n",
       "      <td>0.686205</td>\n",
       "      <td>0.732078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.811500</td>\n",
       "      <td>0.701683</td>\n",
       "      <td>0.818401</td>\n",
       "      <td>0.815720</td>\n",
       "      <td>0.817061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.811500</td>\n",
       "      <td>0.472982</td>\n",
       "      <td>0.858223</td>\n",
       "      <td>0.817573</td>\n",
       "      <td>0.837898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.811500</td>\n",
       "      <td>0.316786</td>\n",
       "      <td>0.877354</td>\n",
       "      <td>0.881534</td>\n",
       "      <td>0.879444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.979100</td>\n",
       "      <td>0.235765</td>\n",
       "      <td>0.886563</td>\n",
       "      <td>0.904933</td>\n",
       "      <td>0.895748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.979100</td>\n",
       "      <td>0.195822</td>\n",
       "      <td>0.920782</td>\n",
       "      <td>0.920070</td>\n",
       "      <td>0.920426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.979100</td>\n",
       "      <td>0.169747</td>\n",
       "      <td>0.933190</td>\n",
       "      <td>0.938921</td>\n",
       "      <td>0.936056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.860900</td>\n",
       "      <td>0.153683</td>\n",
       "      <td>0.939481</td>\n",
       "      <td>0.941709</td>\n",
       "      <td>0.940595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.860900</td>\n",
       "      <td>0.142016</td>\n",
       "      <td>0.944120</td>\n",
       "      <td>0.946680</td>\n",
       "      <td>0.945400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.860900</td>\n",
       "      <td>0.135578</td>\n",
       "      <td>0.945405</td>\n",
       "      <td>0.948372</td>\n",
       "      <td>0.946889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.625700</td>\n",
       "      <td>0.130705</td>\n",
       "      <td>0.946425</td>\n",
       "      <td>0.948669</td>\n",
       "      <td>0.947547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.625700</td>\n",
       "      <td>0.128096</td>\n",
       "      <td>0.947901</td>\n",
       "      <td>0.952419</td>\n",
       "      <td>0.950160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.625700</td>\n",
       "      <td>0.125973</td>\n",
       "      <td>0.948566</td>\n",
       "      <td>0.953588</td>\n",
       "      <td>0.951077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.550200</td>\n",
       "      <td>0.124601</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>0.954135</td>\n",
       "      <td>0.951353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.550200</td>\n",
       "      <td>0.123503</td>\n",
       "      <td>0.949046</td>\n",
       "      <td>0.953153</td>\n",
       "      <td>0.951100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=272, training_loss=1.6684912267853231, metrics={'train_runtime': 634.4067, 'train_samples_per_second': 133.983, 'train_steps_per_second': 0.536, 'total_flos': 4830915362263992.0, 'train_loss': 1.6684912267853231, 'epoch': 16.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2731fe2-6706-47e0-bb41-e915c84c388a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12460056692361832, 'eval_Fbeta_cat1': 0.9485711999839511, 'eval_Fbeta_cat2': 0.9541353925154055, 'eval_final_score': 0.9513532962496782, 'eval_runtime': 1.5941, 'eval_samples_per_second': 470.471, 'eval_steps_per_second': 10.037, 'epoch': 16.0}\n"
     ]
    }
   ],
   "source": [
    "test_metrics = trainer.evaluate()\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e373541-1b07-495a-8357-2b811d500632",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"../models/deberta-improved-weak-ner-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f600a1-516c-4ff8-a814-f48bcc23d4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Applying to the Quiz Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd5ba2-57bd-4d3c-a057-8a02e3ae86a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ---------------------------------------- ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d4ae989-6a9e-4b56-a9bd-3c4157504f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = (\n",
    "    pd.read_csv(\"../data/Listing_Titles.tsv\", sep=\"\\t\", keep_default_na=False, na_values=None)\n",
    "      .query(\"5001 <= `Record Number` <= 30000\")               # <- slice\n",
    ")\n",
    "\n",
    "# keep tokens AND metadata so we can write them back later\n",
    "quiz[\"tokens\"] = quiz[\"Title\"].str.split()\n",
    "quiz_ds = Dataset.from_pandas(\n",
    "    quiz[[\"Record Number\",\"Category\",\"tokens\"]],   # no Title column needed\n",
    "    preserve_index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "814f6016-394d-4f6e-9bb0-d0b9350b02d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "allow = (\n",
    "    tagged.groupby(\"Category\")[\"Tag\"]\n",
    "          .apply(lambda s: {t for t in s.unique() if t and t != \"O\"})\n",
    "          .to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbb11735-2aeb-4a03-b7e6-9a9396c151a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bf3e54927a4c6db91e4bc59d1834e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tok_quiz(batch):\n",
    "    enc = tok(\n",
    "        batch[\"tokens\"],\n",
    "        is_split_into_words=True,\n",
    "        padding=False,  # CHANGED: Let collator handle padding\n",
    "        truncation=True,\n",
    "        max_length=256  # INCREASED\n",
    "    )\n",
    "    \n",
    "    enc[\"labels\"] = [[-100] * len(ids) for ids in enc[\"input_ids\"]]\n",
    "    enc[\"word_ids\"] = [enc.word_ids(i) for i in range(len(enc[\"input_ids\"]))]\n",
    "    enc[\"category_id\"] = batch[\"Category\"]\n",
    "    enc[\"record_id\"] = batch[\"Record Number\"]\n",
    "    enc[\"tokens\"] = batch[\"tokens\"]\n",
    "    return enc\n",
    "\n",
    "quiz_ds = Dataset.from_pandas(\n",
    "    quiz[[\"Record Number\",\"Category\",\"tokens\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "tokenised_quiz = quiz_ds.map(tok_quiz, batched=True, remove_columns=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ee0d06e-793c-4638-9aa9-685473ea46a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.compute_metrics = None # Don't run metrics on the quiz set\n",
    "pred_logits = trainer.predict(tokenised_quiz).predictions\n",
    "pred_ids    = pred_logits.argmax(-1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7777c128-643d-45c9-b7ef-ce94a16c5f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode predictions\n",
    "records = []\n",
    "\n",
    "for i, ex in enumerate(tokenised_quiz):\n",
    "    rec = int(ex[\"record_id\"])\n",
    "    cat = int(ex[\"category_id\"])\n",
    "    words = ex[\"tokens\"]\n",
    "    wids = ex[\"word_ids\"]\n",
    "    labs = [id2label[idx] if idx != -100 else \"O\" for idx in pred_ids[i]]\n",
    "    \n",
    "    # Keep only first sub-word label per word\n",
    "    word_labels = []\n",
    "    prev_wid = None\n",
    "    for wid, lab in zip(wids, labs):\n",
    "        if wid is not None and wid != prev_wid:\n",
    "            word_labels.append((wid, lab))\n",
    "            prev_wid = wid\n",
    "    \n",
    "    # Decode entities correctly\n",
    "    current_tokens = []\n",
    "    current_tag = None\n",
    "    \n",
    "    for wid, label in word_labels:\n",
    "        word = words[wid]\n",
    "        \n",
    "        if label == \"O\":\n",
    "            # Flush any current entity\n",
    "            if current_tokens and current_tag:\n",
    "                records.append((rec, cat, current_tag, \" \".join(current_tokens)))\n",
    "                current_tokens = []\n",
    "                current_tag = None\n",
    "            # Add O token\n",
    "            records.append((rec, cat, \"O\", word))\n",
    "            continue\n",
    "        \n",
    "        prefix, tag = label.split(\"-\", 1)\n",
    "        \n",
    "        # Check if tag is legal for this category\n",
    "        if tag not in allow[cat]:\n",
    "            continue\n",
    "        \n",
    "        if prefix == \"B\":\n",
    "            # NEW entity starts - flush previous\n",
    "            if current_tokens and current_tag:\n",
    "                records.append((rec, cat, current_tag, \" \".join(current_tokens)))\n",
    "            # Start new entity\n",
    "            current_tokens = [word]\n",
    "            current_tag = tag\n",
    "        elif prefix == \"I\":\n",
    "            # Continuation of entity\n",
    "            if tag == current_tag:\n",
    "                current_tokens.append(word)\n",
    "            else:\n",
    "                # I- tag doesn't match current - treat as new entity (model error)\n",
    "                if current_tokens and current_tag:\n",
    "                    records.append((rec, cat, current_tag, \" \".join(current_tokens)))\n",
    "                current_tokens = [word]\n",
    "                current_tag = tag\n",
    "    \n",
    "    # Flush final entity\n",
    "    if current_tokens and current_tag:\n",
    "        records.append((rec, cat, current_tag, \" \".join(current_tokens)))\n",
    "\n",
    "# Filter out O tags for submission\n",
    "submission = pd.DataFrame(records, columns=[\"Record Number\", \"Category\", \"Tag\", \"Token\"])\n",
    "submission = submission[submission[\"Tag\"] != \"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67848059-6006-4294-a390-c8ee7c12e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BEFORE saving submission, validate categories\n",
    "quiz_categories = quiz.set_index(\"Record Number\")[\"Category\"].to_dict()\n",
    "\n",
    "# Validate each submission row\n",
    "for idx, row in submission.iterrows():\n",
    "    rec_num = row[\"Record Number\"]\n",
    "    expected_cat = quiz_categories.get(rec_num)\n",
    "    if row[\"Category\"] != expected_cat:\n",
    "        print(f\"⚠️ Category mismatch at record {rec_num}!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2da166f-eaa6-420a-bf48-479682acdc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "submission.to_csv(\n",
    "    \"../results/deberta-improved-weak-ner-finetuned-1.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=False,\n",
    "    index=False,\n",
    "    encoding=\"utf-8\",\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    escapechar=\"\\\\\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c19fc911-96c6-4c08-8305-1a8a6bedf9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del model, trainer            # or any large tensors / optimizers\n",
    "gc.collect()                  # Python-side ref-count sweep\n",
    "torch.cuda.empty_cache()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e8198-58bf-4b45-8e1b-5b958d88bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENSEMBLE TRY ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1714403-6e0f-499b-b6fc-7e2f27d7328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_model(seed, model_name, train_dataset):\n",
    "    \"\"\"Train one model with specific seed.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Model {seed} - {model_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Set seed\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # Reinitialize model (fresh weights)\n",
    "    cfg = AutoConfig.from_pretrained(\n",
    "        base_model,\n",
    "        num_labels=len(label_list),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "    \n",
    "    model = CatAwareCRF(\n",
    "        cfg,\n",
    "        num_labels=len(label_list),\n",
    "        allow_mask=allow_mask,\n",
    "        base_model_name=base_model,\n",
    "        use_dapt=True,\n",
    "        label_smoothing=0.005\n",
    "    ).to(device)\n",
    "    \n",
    "    # Training args\n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"../models/deberta-ner-ensemble-seed{seed}\",\n",
    "        \n",
    "        # A100-optimized batch size\n",
    "        per_device_train_batch_size=48,   # ✅ Use A100 memory efficiently\n",
    "        gradient_accumulation_steps=3,    # ✅ Effective = 144\n",
    "        \n",
    "        # Learning rate\n",
    "        learning_rate=4e-6,               # ✅ Revert to what worked\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.15,\n",
    "        max_grad_norm=1.0,\n",
    "        \n",
    "        # Epochs\n",
    "        num_train_epochs=45,             # ✅ Proven sweet spot\n",
    "        \n",
    "        # Optimization\n",
    "        optim=\"adamw_torch_fused\",        # ✅ Fastest for A100\n",
    "        lr_scheduler_type=\"cosine_with_restarts\",\n",
    "        \n",
    "        # Mixed precision\n",
    "        bf16=True,\n",
    "        fp16=False,\n",
    "        \n",
    "        # Evaluation\n",
    "        eval_strategy=\"no\",\n",
    "        save_strategy=\"no\",\n",
    "        \n",
    "        # Logging\n",
    "        logging_steps=25,\n",
    "        \n",
    "        # Efficiency\n",
    "        dataloader_num_workers=16,\n",
    "        dataloader_pin_memory=True,\n",
    "        gradient_checkpointing=False,\n",
    "        \n",
    "        # Seed\n",
    "        seed=seed,\n",
    "        data_seed=seed,\n",
    "        \n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        data_collator=new_collator,\n",
    "        processing_class=tok,\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save\n",
    "    trainer.save_model(f\"../models/deberta-ner-ensemble-seed{seed}-final-confidence\")\n",
    "    \n",
    "    return f\"../models/deberta-ner-ensemble-seed{seed}-final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ded08f-a048-42ab-a9b4-f5b69444c7e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model 42 - model_42\n",
      "============================================================\n",
      "\n",
      "Loading DAPT encoder from ../models/deberta-improved-weak-ner-mk-2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2100' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2100/2100 30:24, Epoch 60/60]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>13.272400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>12.692300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>11.505600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>9.722000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>7.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.546100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>4.010600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.235500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.870800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.686900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.591900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.508700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.466100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.426300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.388200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.369600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.356000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.338300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.315800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.304600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.301300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.295400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.272200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.278000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.263200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.262900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.258400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.247900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.246600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.230100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.242100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.234500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.218400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.230900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.217100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.220200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.211900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.206000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.207500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.199700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>2.211100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.193000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>2.197400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.188100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>2.193300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.187600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>2.189500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>2.190800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.181700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>2.187600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.176600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.173900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.179500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>2.174700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.172500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>2.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.170700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>2.169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.168500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>2.169100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.169800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>2.168500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.165100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>2.160300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.171200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>2.168100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.159900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>2.162800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>2.164700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>2.159900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.173300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>2.160400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>2.164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>2.166700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.160100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>2.154800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>2.160400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>2.166500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.159500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>2.160300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>2.162200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>2.171800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.165900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model 123 - model_123\n",
      "============================================================\n",
      "\n",
      "Loading DAPT encoder from ../models/deberta-improved-weak-ner-mk-2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2100' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2100/2100 30:22, Epoch 60/60]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>12.974100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>12.384400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>11.246100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>9.572400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>7.506100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.478700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>4.069800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.264000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.883900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.669000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.564000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.490300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.433500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.393500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.362600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.343200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.319900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.301600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.296500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.279900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.263100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.256800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.248700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.237400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.232100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.234700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.216300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.210400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.208700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.194800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.191200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.191100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.185100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.184900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.171900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.179500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.171800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.165400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>2.167300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.164600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>2.162300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.153200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>2.158500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.153300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>2.153600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>2.150400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>2.140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.153300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.137800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.139400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>2.140900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.139700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>2.133900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.138300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>2.129200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.138400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>2.136800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.123400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>2.132100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>2.130500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.126000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>2.129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.129800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>2.127200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>2.127100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>2.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.128900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>2.119200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>2.129800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>2.123600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>2.129400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>2.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>2.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>2.122400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>2.126300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>2.126700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.125200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model 456 - model_456\n",
      "============================================================\n",
      "\n",
      "Loading DAPT encoder from ../models/deberta-improved-weak-ner-mk-2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2100' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2100/2100 30:27, Epoch 60/60]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>13.412200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>12.840900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>11.681200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>9.869100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>7.477800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.338400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>3.962000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.225400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.864500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.583700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.513800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.465400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.426200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.391600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.367600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.348600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.336700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.317100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.300200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.306900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.284100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.272100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.268200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.254700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.260900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.249500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.239300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.251700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.218600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.230300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.231400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.206100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.231400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.215900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.211200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.215800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.200700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.206200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>2.196800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.206000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>2.193100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.192400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>2.185700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.193300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>2.182500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.184500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>2.185300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.177500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>2.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.186600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.173200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.176200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>2.175900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.174300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>2.170700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.170700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>2.163100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.164200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>2.174800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.163000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>2.162300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.162900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>2.169900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.161200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>2.165400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.166900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>2.156100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>2.164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>2.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.160800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>2.161900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>2.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>2.161900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.165200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>2.154900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>2.161200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>2.158300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.158800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>2.159800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>2.155300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>2.158100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.161400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model 789 - model_789\n",
      "============================================================\n",
      "\n",
      "Loading DAPT encoder from ../models/deberta-improved-weak-ner-mk-2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2100' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2100/2100 30:33, Epoch 60/60]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>12.480100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>11.873900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>10.665000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>8.863500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>6.806900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>3.729800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.095400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.822800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.665700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.566800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.501700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.443100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.420200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.384700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.365400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.347600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.344600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.314200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.320900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.297900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.294500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.283900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.277700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.268800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.266800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.254100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.253400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.241500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.247200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.238300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.228900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.237100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.220700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.221700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.219100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.209600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.214300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.212200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.207800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>2.196300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.203100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>2.191800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.194800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>2.194000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.184500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>2.188000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.197100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>2.180600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.179900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>2.187400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.178500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.177400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>2.177600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.167400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>2.175100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.169200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>2.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.173500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>2.167200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.172200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>2.165600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>2.164200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.163000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>2.165200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.165700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>2.156000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>2.162200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>2.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.163400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>2.155700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>2.163800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>2.163900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.159300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>2.161800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>2.163400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>2.162900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.165100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>2.158100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>2.160200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>2.167100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.156000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model 2024 - model_2024\n",
      "============================================================\n",
      "\n",
      "Loading DAPT encoder from ../models/deberta-improved-weak-ner-mk-2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2100' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2100/2100 30:28, Epoch 60/60]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>13.176800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>12.594400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>11.448800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>9.726800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>7.521700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.443700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>3.976000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.221800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.880800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.681200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.571700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.498300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.458700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.386100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.372400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.336700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.324400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.308500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.307800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.294800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.273900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.283600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.272600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.257000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.245900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.241900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.244100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.230900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.237600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.218400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.227000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.222900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.215900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.209300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.210700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.186100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>2.218500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.196700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>2.200900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.195800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>2.189500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.197400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>2.188400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.181000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>2.187000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.182100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>2.177800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.189900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.177200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.184800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>2.170100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.177400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>2.173100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.169800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>2.173500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.170300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>2.162200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.164700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>2.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.169300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>2.166500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.168200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>2.168400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.152700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>2.172600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>2.165300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>2.167100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.163300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>2.167800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>2.160300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>2.161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.164800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>2.165800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>2.162900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>2.156100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.160900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>2.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>2.159500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>2.161600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.166400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Trained 5 models\n",
      "Ensemble models saved at:\n",
      "  - ../models/deberta-ner-ensemble-seed42-final\n",
      "  - ../models/deberta-ner-ensemble-seed123-final\n",
      "  - ../models/deberta-ner-ensemble-seed456-final\n",
      "  - ../models/deberta-ner-ensemble-seed789-final\n",
      "  - ../models/deberta-ner-ensemble-seed2024-final\n"
     ]
    }
   ],
   "source": [
    "# Train 10 models\n",
    "ensemble_seeds = [42, 123, 456, 789, 2024]\n",
    "ensemble_paths = []\n",
    "\n",
    "for seed in ensemble_seeds:\n",
    "    model_path = train_single_model(seed, f\"model_{seed}\")\n",
    "    ensemble_paths.append(model_path)\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\n✓ Trained {len(ensemble_paths)} models\")\n",
    "print(\"Ensemble models saved at:\")\n",
    "for path in ensemble_paths:\n",
    "    print(f\"  - {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a4f3ccf-a467-441e-a8d2-6021c2e2787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff9cd99-1d2a-4606-bc7c-83b652759550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef6891e17144b12aad61968f774f455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../models/deberta-ner-ensemble-seed42-final...\n",
      "Loading model from ../models/deberta-ner-ensemble-seed123-final...\n",
      "Loading model from ../models/deberta-ner-ensemble-seed456-final...\n",
      "Loading model from ../models/deberta-ner-ensemble-seed789-final...\n",
      "Loading model from ../models/deberta-ner-ensemble-seed2024-final...\n",
      "Predicting with model 1/5...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model 2/5...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model 3/5...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model 4/5...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model 5/5...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing majority voting...\n",
      "✓ Ensemble predictions shape: (25000, 49)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ENSEMBLE PREDICTION (Majority Voting)\n",
    "# ============================================================================\n",
    "# ensemble_paths = [f\"../models/deberta-ner-ensemble-seed{42}-final\", f\"../models/deberta-ner-ensemble-seed{123}-final\", f\"../models/deberta-ner-ensemble-seed{456}-final\", f\"../models/deberta-ner-ensemble-seed{789}-final\", f\"../models/deberta-ner-ensemble-seed{2024}-final\"]\n",
    "def load_ensemble_models(model_paths):\n",
    "    \"\"\"Load all trained models.\"\"\"\n",
    "    models = []\n",
    "    \n",
    "    for path in model_paths:\n",
    "        print(f\"Loading model from {path}...\")\n",
    "        \n",
    "        # Let AutoModel handle the loading\n",
    "        from transformers import AutoModelForTokenClassification\n",
    "        \n",
    "        # This won't work directly, so use manual approach:\n",
    "        cfg = AutoConfig.from_pretrained(path)\n",
    "        \n",
    "        # Reinitialize the full model structure\n",
    "        model = CatAwareCRF(\n",
    "            cfg,\n",
    "            num_labels=len(label_list),\n",
    "            allow_mask=allow_mask,\n",
    "            base_model_name=None,\n",
    "            use_dapt=True\n",
    "        )\n",
    "        \n",
    "        # Now load the task-specific layers\n",
    "        from safetensors.torch import load_file\n",
    "        state_dict = load_file(f\"{path}/model.safetensors\")\n",
    "        model.load_state_dict(state_dict)  # Load everything!\n",
    "        \n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    \n",
    "    return models\n",
    "\n",
    "\n",
    "def ensemble_predict(models, tokenised_quiz, trainer_args):\n",
    "    \"\"\"\n",
    "    Get predictions from all models and vote.\n",
    "    Returns: voted predictions (batch_size, seq_len)\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"Predicting with model {i+1}/{len(models)}...\")\n",
    "        \n",
    "        # Create temporary trainer for prediction\n",
    "        temp_trainer = Trainer(\n",
    "            model=model,\n",
    "            args=trainer_args,\n",
    "            data_collator=new_collator,\n",
    "            processing_class=tok,\n",
    "        )\n",
    "        \n",
    "        # Ensure labels are NOT passed (triggers decode path)\n",
    "        pred_output = temp_trainer.predict(tokenised_quiz)\n",
    "        pred_output_array = pred_output.predictions\n",
    "        \n",
    "        # Check shape and handle accordingly\n",
    "        if pred_output_array.ndim == 3:\n",
    "            # Training mode was triggered - logits returned\n",
    "            pred_ids = pred_output_array.argmax(-1)\n",
    "        elif pred_output_array.ndim == 2:\n",
    "            # Inference mode - already decoded IDs\n",
    "            pred_ids = pred_output_array\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected prediction shape: {pred_output_array.shape}\")\n",
    "        \n",
    "        # CRF already decoded, predictions are label IDs\n",
    "        all_predictions.append(pred_ids)\n",
    "        \n",
    "        # Clear memory\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Voting: majority wins\n",
    "    print(\"Performing majority voting...\")\n",
    "    all_predictions = np.array(all_predictions)  # (num_models, batch_size, seq_len)\n",
    "    \n",
    "    voted_predictions = []\n",
    "    for i in range(all_predictions.shape[1]):  # For each example\n",
    "        example_preds = all_predictions[:, i, :]  # (num_models, seq_len)\n",
    "        \n",
    "        # Majority vote per token\n",
    "        voted_seq = []\n",
    "        for j in range(example_preds.shape[1]):  # For each token\n",
    "            token_votes = example_preds[:, j]\n",
    "            \n",
    "            # Ignore -100 (padding/special tokens)\n",
    "            valid_votes = token_votes[token_votes != -100]\n",
    "            \n",
    "            if len(valid_votes) == 0:\n",
    "                voted_seq.append(-100)\n",
    "            else:\n",
    "                # Most common prediction\n",
    "                from collections import Counter\n",
    "                vote_counts = Counter(valid_votes)\n",
    "                majority_vote = vote_counts.most_common(1)[0][0]\n",
    "                # voted_seq.append(majority_vote)\n",
    "                voted_seq.append(int(majority_vote))\n",
    "        \n",
    "        voted_predictions.append(voted_seq)\n",
    "    \n",
    "    # return np.array(voted_predictions)\n",
    "    return np.array(voted_predictions, dtype=np.int64)\n",
    "    \n",
    "# ============================================================================\n",
    "# LOAD QUIZ DATA\n",
    "# ============================================================================\n",
    "\n",
    "quiz = (\n",
    "    pd.read_csv(\"../data/Listing_Titles.tsv\", sep=\"\\t\", \n",
    "                keep_default_na=False, na_values=None)\n",
    "    .query(\"5001 <= `Record Number` <= 30000\")\n",
    ")\n",
    "\n",
    "quiz[\"tokens\"] = quiz[\"Title\"].str.split()\n",
    "quiz_ds = Dataset.from_pandas(\n",
    "    quiz[[\"Record Number\", \"Category\", \"tokens\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "\n",
    "def tok_quiz(batch):\n",
    "    enc = tok(\n",
    "        batch[\"tokens\"],\n",
    "        is_split_into_words=True,\n",
    "        padding=False,\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "    \n",
    "    enc[\"labels\"] = [[-100] * len(ids) for ids in enc[\"input_ids\"]]\n",
    "    enc[\"word_ids\"] = [enc.word_ids(i) for i in range(len(enc[\"input_ids\"]))]\n",
    "    enc[\"category_id\"] = batch[\"Category\"]\n",
    "    enc[\"record_id\"] = batch[\"Record Number\"]\n",
    "    enc[\"tokens\"] = batch[\"tokens\"]\n",
    "    return enc\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(base_model)\n",
    "tokenised_quiz = quiz_ds.map(tok_quiz, batched=True, remove_columns=[])\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ENSEMBLE INFERENCEFl\n",
    "# ============================================================================\n",
    "\n",
    "# Load all ensemble models\n",
    "\n",
    "ensemble_models = load_ensemble_models(ensemble_paths)\n",
    "\n",
    "# Dummy trainer args for prediction\n",
    "dummy_args = TrainingArguments(\n",
    "    output_dir=\"../temp\",\n",
    "    per_device_eval_batch_size=48,\n",
    "    dataloader_num_workers=16,\n",
    "    bf16=True,\n",
    ")\n",
    "\n",
    "# Get ensemble predictions\n",
    "pred_ids = ensemble_predict(ensemble_models, tokenised_quiz, dummy_args)\n",
    "\n",
    "print(f\"✓ Ensemble predictions shape: {pred_ids.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eda9817b-d9bc-431d-8f0a-9aa0aabd620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode predictions\n",
    "records = []\n",
    "\n",
    "for i, ex in enumerate(tokenised_quiz):\n",
    "    rec = int(ex[\"record_id\"])\n",
    "    cat = int(ex[\"category_id\"])\n",
    "    words = ex[\"tokens\"]\n",
    "    wids = ex[\"word_ids\"]\n",
    "    labs = [id2label[idx] if idx != -100 else \"O\" for idx in pred_ids[i]]\n",
    "    \n",
    "    # Keep only first sub-word label per word\n",
    "    word_labels = []\n",
    "    prev_wid = None\n",
    "    for wid, lab in zip(wids, labs):\n",
    "        if wid is not None and wid != prev_wid:\n",
    "            word_labels.append((wid, lab))\n",
    "            prev_wid = wid\n",
    "    \n",
    "    # Decode entities correctly\n",
    "    current_tokens = []\n",
    "    current_tag = None\n",
    "    \n",
    "    for wid, label in word_labels:\n",
    "        word = words[wid]\n",
    "        \n",
    "        if label == \"O\":\n",
    "            # Flush any current entity\n",
    "            if current_tokens and current_tag:\n",
    "                records.append((rec, cat, current_tag, \" \".join(current_tokens)))\n",
    "                current_tokens = []\n",
    "                current_tag = None\n",
    "            # Add O token\n",
    "            records.append((rec, cat, \"O\", word))\n",
    "            continue\n",
    "        \n",
    "        prefix, tag = label.split(\"-\", 1)\n",
    "        \n",
    "        # Check if tag is legal for this category\n",
    "        if tag not in allow[cat]:\n",
    "            continue\n",
    "        \n",
    "        if prefix == \"B\":\n",
    "            # NEW entity starts - flush previous\n",
    "            if current_tokens and current_tag:\n",
    "                records.append((rec, cat, current_tag, \" \".join(current_tokens)))\n",
    "            # Start new entity\n",
    "            current_tokens = [word]\n",
    "            current_tag = tag\n",
    "        elif prefix == \"I\":\n",
    "            # Continuation of entity\n",
    "            if tag == current_tag:\n",
    "                current_tokens.append(word)\n",
    "            else:\n",
    "                # I- tag doesn't match current - treat as new entity (model error)\n",
    "                if current_tokens and current_tag:\n",
    "                    records.append((rec, cat, current_tag, \" \".join(current_tokens)))\n",
    "                current_tokens = [word]\n",
    "                current_tag = tag\n",
    "    \n",
    "    # Flush final entity\n",
    "    if current_tokens and current_tag:\n",
    "        records.append((rec, cat, current_tag, \" \".join(current_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e069762f-ff59-48ad-b270-90878bcdaea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 59 labels: ['O', 'B-Anwendung', 'B-Anzahl_Der_Einheiten', 'B-Besonderheiten', 'B-Breite', 'B-Bremsscheiben-Aussendurchmesser', 'B-Bremsscheibenart', 'B-Einbauposition', 'B-Farbe', 'B-Größe']...\n",
      "Gazetteers created for 29 tags\n",
      "  Kompatible_Fahrzeug_Marke: 173 entries\n",
      "  Kompatibles_Fahrzeug_Modell: 1902 entries\n",
      "  Herstellernummer: 1084 entries\n",
      "  Produktart: 196 entries\n",
      "  Im_Lieferumfang_Enthalten: 340 entries\n",
      "  Hersteller: 155 entries\n",
      "  Modell: 40 entries\n",
      "  Einbauposition: 41 entries\n",
      "  Bremsscheiben-Aussendurchmesser: 345 entries\n",
      "  Bremsscheibenart: 45 entries\n",
      "  Oe/Oem_Referenznummer(N): 228 entries\n",
      "  Maßeinheit: 10 entries\n",
      "  Anzahl_Der_Einheiten: 17 entries\n",
      "  Kompatibles_Fahrzeug_Jahr: 183 entries\n",
      "  Produktlinie: 4 entries\n",
      "  Material: 5 entries\n",
      "  Größe: 11 entries\n",
      "  Länge: 3 entries\n",
      "  Breite: 3 entries\n",
      "  Besonderheiten: 31 entries\n",
      "  Menge: 11 entries\n",
      "  Farbe: 1 entries\n",
      "  Stärke: 10 entries\n",
      "  Anwendung: 14 entries\n",
      "  Oberflächenbeschaffenheit: 2 entries\n",
      "  SAE_Viskosität: 2 entries\n",
      "  Zähnezahl: 3 entries\n",
      "  Technologie: 1 entries\n",
      "  Herstellungsland_Und_-Region: 1 entries\n",
      "new records\n"
     ]
    }
   ],
   "source": [
    "def build_gazetteers(tagged_df):\n",
    "    \"\"\"Extract known entities from training data.\"\"\"\n",
    "    \n",
    "    gazetteers = {}\n",
    "    \n",
    "    for tag in tagged_df[\"Tag\"].unique():\n",
    "        if tag and tag != \"O\":\n",
    "            values = set(\n",
    "                tagged_df[tagged_df[\"Tag\"] == tag][\"Token\"]\n",
    "                .str.lower()\n",
    "                .str.strip()\n",
    "                .unique()\n",
    "            )\n",
    "            # Remove very common/short tokens (noise)\n",
    "            gazetteers[tag] = {v for v in values if len(v) > 0}\n",
    "    \n",
    "    return gazetteers\n",
    "\n",
    "\n",
    "# Load tagged data to get all possible tags\n",
    "tagged = pd.read_csv(\n",
    "    \"../data/Tagged_Titles_Train.tsv\",\n",
    "    sep=\"\\t\", keep_default_na=False, na_values=None\n",
    ")\n",
    "\n",
    "\n",
    "# Create BIO label list\n",
    "BASE = set(t for t in tagged[\"Tag\"].unique() if t and t != \"O\")\n",
    "label_list = [\"O\"] + sorted(\n",
    "    f\"{p}-{t}\" for t in BASE for p in (\"B\", \"I\")\n",
    ")\n",
    "label2id = {l: i for i, l in enumerate(label_list)}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "\n",
    "print(f\"Created {len(label_list)} labels: {label_list[:10]}...\")\n",
    "\n",
    "gazetteers = build_gazetteers(tagged)\n",
    "\n",
    "print(f\"Gazetteers created for {len(gazetteers)} tags\")\n",
    "for tag, values in gazetteers.items():\n",
    "    print(f\"  {tag}: {len(values)} entries\")\n",
    "\n",
    "\n",
    "def post_process_predictions(records, gazetteers, allow):\n",
    "    \"\"\"Fix obvious errors using domain knowledge.\"\"\"\n",
    "    corrected = []\n",
    "    \n",
    "    for rec, cat, tag, token in records:\n",
    "        token_lower = token.lower().strip()\n",
    "        \n",
    "        # Rule 1: Check gazetteer exclusivity\n",
    "        if tag != \"O\":\n",
    "            found_tags = [gaz_tag for gaz_tag, entities in gazetteers.items() \n",
    "                         if token_lower in entities and gaz_tag in allow[cat]]\n",
    "            \n",
    "            # If token exclusively in different gazetteer, correct it\n",
    "            if len(found_tags) == 1 and found_tags[0] != tag:\n",
    "                tag = found_tags[0]\n",
    "        \n",
    "        # Rule 2: Known brand/manufacturer disambiguation\n",
    "        known_brands = {'bmw', 'audi', 'vw', 'mercedes', 'opel', 'ford'}\n",
    "        known_manufacturers = {'bosch', 'ate', 'brembo', 'zimmermann', 'febi'}\n",
    "        \n",
    "        if token_lower in known_brands and tag == 'Hersteller':\n",
    "            # Likely should be Marke\n",
    "            tag = 'Kompatible_Fahrzeug_Marke'\n",
    "        elif token_lower in known_manufacturers and tag == 'Kompatible_Fahrzeug_Marke':\n",
    "            # Likely should be Hersteller\n",
    "            tag = 'Hersteller'\n",
    "        \n",
    "        # Rule 3: Position indicators\n",
    "        position_words = {'va', 'ha', 'vorne', 'hinten', 'links', 'rechts', 'vl', 'vr', 'hl', 'hr'}\n",
    "        if token_lower in position_words and tag != 'Einbauposition':\n",
    "            tag = 'Einbauposition'\n",
    "        \n",
    "        # Rule 4: Number patterns for Anzahl\n",
    "        if token.isdigit() and tag != 'Anzahl_Der_Einheiten':\n",
    "            # Check context - if followed by \"stück\", \"x\", etc.\n",
    "            # (You'd need to track context here)\n",
    "            pass\n",
    "        \n",
    "        corrected.append((rec, cat, tag, token))\n",
    "    \n",
    "    return corrected\n",
    "\n",
    "# Apply after decoding\n",
    "records = post_process_predictions(records, gazetteers, allow)\n",
    "\n",
    "print(\"new records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d05af5f-9b92-4e6f-a4dd-81af63f55da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out O tags for submission\n",
    "submission = pd.DataFrame(records, columns=[\"Record Number\", \"Category\", \"Tag\", \"Token\"])\n",
    "submission = submission[submission[\"Tag\"] != \"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "950c36aa-b555-47f9-b911-f61f4b24248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE saving submission, validate categories\n",
    "quiz_categories = quiz.set_index(\"Record Number\")[\"Category\"].to_dict()\n",
    "\n",
    "# Validate each submission row\n",
    "for idx, row in submission.iterrows():\n",
    "    rec_num = row[\"Record Number\"]\n",
    "    expected_cat = quiz_categories.get(rec_num)\n",
    "    if row[\"Category\"] != expected_cat:\n",
    "        print(f\"⚠️ Category mismatch at record {rec_num}!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77459c27-f512-4c40-8185-2dfd79882a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "submission.to_csv(\n",
    "    \"../results/weak-nerMK2-smooth0-01-ensemble-120-epochs.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=False,\n",
    "    index=False,\n",
    "    encoding=\"utf-8\",\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    escapechar=\"\\\\\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1c94b-820b-4709-b301-ed912c16d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFIDENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bee3ad8-2d35-450c-b633-6413f05ce520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../models/deberta-ner-ensemble-seed42-final...\n",
      "Loading model from ../models/deberta-ner-ensemble-seed123-final...\n",
      "Loading model from ../models/deberta-ner-ensemble-seed456-final...\n",
      "Loading model from ../models/deberta-ner-ensemble-seed789-final...\n",
      "Loading model from ../models/deberta-ner-ensemble-seed2024-final...\n"
     ]
    }
   ],
   "source": [
    "ensemble_paths = [f\"../models/deberta-ner-ensemble-seed{42}-final\", f\"../models/deberta-ner-ensemble-seed{123}-final\", f\"../models/deberta-ner-ensemble-seed{456}-final\", f\"../models/deberta-ner-ensemble-seed{789}-final\", f\"../models/deberta-ner-ensemble-seed{2024}-final\"]\n",
    "def load_ensemble_models(model_paths):\n",
    "    \"\"\"Load all trained models.\"\"\"\n",
    "    models = []\n",
    "    \n",
    "    for path in model_paths:\n",
    "        print(f\"Loading model from {path}...\")\n",
    "        \n",
    "        # Let AutoModel handle the loading\n",
    "        from transformers import AutoModelForTokenClassification\n",
    "        \n",
    "        # This won't work directly, so use manual approach:\n",
    "        cfg = AutoConfig.from_pretrained(path)\n",
    "        \n",
    "        # Reinitialize the full model structure\n",
    "        model = CatAwareCRF(\n",
    "            cfg,\n",
    "            num_labels=len(label_list),\n",
    "            allow_mask=allow_mask,\n",
    "            base_model_name=None,\n",
    "            use_dapt=True\n",
    "        )\n",
    "        \n",
    "        # Now load the task-specific layers\n",
    "        from safetensors.torch import load_file\n",
    "        state_dict = load_file(f\"{path}/model.safetensors\")\n",
    "        model.load_state_dict(state_dict)  # Load everything!\n",
    "        \n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    \n",
    "    return models\n",
    "\n",
    "ensemble_models = load_ensemble_models(ensemble_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b1d887a-1a01-407a-8d19-7e4f3e0f2a5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd959402c844526818595dba981eddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions from all models...\n",
      "Predicting with model 1/5...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model 2/5...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model 3/5...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='728' max='938' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [728/938 01:48 < 00:31, 6.69 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 118\u001b[39m\n\u001b[32m    113\u001b[39m tokenised_unlabeled = unlabeled_ds.map(tok_quiz, batched=\u001b[38;5;28;01mTrue\u001b[39;00m, remove_columns=[])\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# Get high-confidence predictions\u001b[39;00m\n\u001b[32m    116\u001b[39m \n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# Use this instead\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m confident_preds = \u001b[43mget_confident_predictions_fast\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensemble_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenised_unlabeled\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(confident_preds)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m high-confidence examples\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mget_confident_predictions_fast\u001b[39m\u001b[34m(ensemble_models, unlabeled_data)\u001b[39m\n\u001b[32m     28\u001b[39m model.eval()\n\u001b[32m     30\u001b[39m trainer = Trainer(\n\u001b[32m     31\u001b[39m     model=model,\n\u001b[32m     32\u001b[39m     args=dummy_args,\n\u001b[32m     33\u001b[39m     data_collator=new_collator,\n\u001b[32m     34\u001b[39m     processing_class=tok,\n\u001b[32m     35\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m predictions = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43munlabeled_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m pred_array = predictions.predictions\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Handle argmax if needed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/transformers/trainer.py:4251\u001b[39m, in \u001b[36mTrainer.predict\u001b[39m\u001b[34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4248\u001b[39m start_time = time.time()\n\u001b[32m   4250\u001b[39m eval_loop = \u001b[38;5;28mself\u001b[39m.prediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluation_loop\n\u001b[32m-> \u001b[39m\u001b[32m4251\u001b[39m output = \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPrediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[32m   4253\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4254\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n\u001b[32m   4255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_jit_compilation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/transformers/trainer.py:4368\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4365\u001b[39m         batch_size = observed_batch_size\n\u001b[32m   4367\u001b[39m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4368\u001b[39m losses, logits, labels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4369\u001b[39m main_input_name = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmain_input_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4370\u001b[39m inputs_decode = (\n\u001b[32m   4371\u001b[39m     \u001b[38;5;28mself\u001b[39m._prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args.include_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4372\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/transformers/trainer.py:4584\u001b[39m, in \u001b[36mTrainer.prediction_step\u001b[39m\u001b[34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[39m\n\u001b[32m   4582\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[32m   4583\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4584\u001b[39m         loss, outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   4585\u001b[39m     loss = loss.detach().mean()\n\u001b[32m   4587\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/transformers/trainer.py:3810\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3808\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3809\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3810\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3811\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3812\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py:818\u001b[39m, in \u001b[36mconvert_outputs_to_fp32.<locals>.forward\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    817\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py:806\u001b[39m, in \u001b[36mConvertOutputsToFp32.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    805\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m806\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:44\u001b[39m, in \u001b[36mautocast_decorator.<locals>.decorate_autocast\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_autocast\u001b[39m(*args, **kwargs):\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mCatAwareCRF.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, labels, category_id, **ignored)\u001b[39m\n\u001b[32m     73\u001b[39m smooth_labels = safe_labels.float()\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# CRF expects hard labels, so apply smoothing to loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m log_lik = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcrf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtoken_mean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Add regularization term\u001b[39;00m\n\u001b[32m     78\u001b[39m uniform_dist = torch.full_like(logits, \u001b[32m1.0\u001b[39m / num_labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/torchcrf/__init__.py:102\u001b[39m, in \u001b[36mCRF.forward\u001b[39m\u001b[34m(self, emissions, tags, mask, reduction)\u001b[39m\n\u001b[32m     99\u001b[39m     mask = mask.transpose(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# shape: (batch_size,)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m numerator = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43memissions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# shape: (batch_size,)\u001b[39;00m\n\u001b[32m    104\u001b[39m denominator = \u001b[38;5;28mself\u001b[39m._compute_normalizer(emissions, mask)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/software-testing-llm/.venv/lib/python3.12/site-packages/torchcrf/__init__.py:196\u001b[39m, in \u001b[36mCRF._compute_score\u001b[39m\u001b[34m(self, emissions, tags, mask)\u001b[39m\n\u001b[32m    192\u001b[39m     score += \u001b[38;5;28mself\u001b[39m.transitions[tags[i - \u001b[32m1\u001b[39m], tags[i]] * mask[i]\n\u001b[32m    194\u001b[39m     \u001b[38;5;66;03m# Emission score for next tag, only added if next timestep is valid (mask == 1)\u001b[39;00m\n\u001b[32m    195\u001b[39m     \u001b[38;5;66;03m# shape: (batch_size,)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     score += emissions[i, \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m, tags[i]] * mask[i]\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# End transition score\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# shape: (batch_size,)\u001b[39;00m\n\u001b[32m    200\u001b[39m seq_ends = mask.long().sum(dim=\u001b[32m0\u001b[39m) - \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ACTIVE LEARNING: Find confident predictions to add to training\n",
    "# ============================================================================\n",
    "from tqdm import tqdm\n",
    "def get_confident_predictions_fast(ensemble_models, unlabeled_data):\n",
    "    \"\"\"\n",
    "    Fast batch prediction using Trainer.\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    from tqdm.auto import tqdm\n",
    "    \n",
    "    # Trainer args for fast batch prediction\n",
    "    dummy_args = TrainingArguments(\n",
    "        output_dir=\"../temp\",\n",
    "        per_device_eval_batch_size=128,  # ✅ Batch processing\n",
    "        dataloader_num_workers=16,\n",
    "        bf16=True,\n",
    "    )\n",
    "    \n",
    "    high_confidence_examples = []\n",
    "    \n",
    "    # Get predictions from all models (batched)\n",
    "    print(\"Getting predictions from all models...\")\n",
    "    all_model_predictions = []\n",
    "    \n",
    "    for model_idx, model in enumerate(ensemble_models):\n",
    "        print(f\"Predicting with model {model_idx+1}/{len(ensemble_models)}...\")\n",
    "        model.eval()\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=dummy_args,\n",
    "            data_collator=new_collator,\n",
    "            processing_class=tok,\n",
    "        )\n",
    "        \n",
    "        predictions = trainer.predict(unlabeled_data)\n",
    "        pred_array = predictions.predictions\n",
    "        \n",
    "        # Handle argmax if needed\n",
    "        if pred_array.ndim == 3:\n",
    "            pred_array = pred_array.argmax(-1)\n",
    "        \n",
    "        all_model_predictions.append(pred_array)\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Check agreement\n",
    "    print(\"Checking agreement across models...\")\n",
    "    all_model_predictions = np.array(all_model_predictions)  # (num_models, num_examples, seq_len)\n",
    "    \n",
    "    for example_idx in tqdm(range(len(unlabeled_data))):\n",
    "        example = unlabeled_data[example_idx]\n",
    "        example_preds = all_model_predictions[:, example_idx, :]  # (num_models, seq_len)\n",
    "        \n",
    "        # Check agreement for each token\n",
    "        agreed_sequence = []\n",
    "        all_agree = True\n",
    "        \n",
    "        for token_idx in range(example_preds.shape[1]):\n",
    "            token_preds = example_preds[:, token_idx]\n",
    "            \n",
    "            # Skip padding\n",
    "            if token_preds[0] == -100:\n",
    "                continue\n",
    "            \n",
    "            # All models must agree\n",
    "            if len(set(token_preds)) != 1:\n",
    "                all_agree = False\n",
    "                break\n",
    "            \n",
    "            agreed_sequence.append(int(token_preds[0]))\n",
    "        \n",
    "        if all_agree and len(agreed_sequence) > 0:\n",
    "            high_confidence_examples.append({\n",
    "                'example': example,\n",
    "                'predicted_labels': agreed_sequence,\n",
    "            })\n",
    "    \n",
    "    return high_confidence_examples\n",
    "\n",
    "\n",
    "# Run on unlabeled data (records 5001-30000 that aren't in quiz scoring)\n",
    "df_unsup = pd.read_csv(\"../data/Listing_Titles.tsv\",\n",
    "    sep=\"\\t\", keep_default_na=False, na_values=None\n",
    ")\n",
    "\n",
    "unlabeled_titles = df_unsup[\n",
    "    (df_unsup[\"Record Number\"] >= 30001) & \n",
    "    (df_unsup[\"Record Number\"] <= 200000)\n",
    "].sample(120000, random_state=42)  # Sample 50K\n",
    "\n",
    "# Tokenize\n",
    "unlabeled_titles[\"tokens\"] = unlabeled_titles[\"Title\"].str.split()\n",
    "unlabeled_ds = Dataset.from_pandas(unlabeled_titles[[\"Record Number\", \"Category\", \"tokens\"]])\n",
    "\n",
    "def tok_quiz(batch):\n",
    "    enc = tok(\n",
    "        batch[\"tokens\"],\n",
    "        is_split_into_words=True,\n",
    "        padding=False,\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "    \n",
    "    enc[\"labels\"] = [[-100] * len(ids) for ids in enc[\"input_ids\"]]\n",
    "    enc[\"word_ids\"] = [enc.word_ids(i) for i in range(len(enc[\"input_ids\"]))]\n",
    "    enc[\"category_id\"] = batch[\"Category\"]\n",
    "    enc[\"record_id\"] = batch[\"Record Number\"]\n",
    "    enc[\"tokens\"] = batch[\"tokens\"]\n",
    "    return enc\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(ensemble_paths[0])\n",
    "tokenised_unlabeled = unlabeled_ds.map(tok_quiz, batched=True, remove_columns=[])\n",
    "\n",
    "# Get high-confidence predictions\n",
    "\n",
    "# Use this instead\n",
    "confident_preds = get_confident_predictions_fast(\n",
    "    ensemble_models, \n",
    "    tokenised_unlabeled\n",
    ")\n",
    "print(f\"Found {len(confident_preds)} high-confidence examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b1fbb-205e-44f5-be2f-179b4d4f0d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions from model 1...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions from model 2...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='937' max='938' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [937/938 02:16 < 00:00, 6.85 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_confident_predictions_two_models(ensemble_models, unlabeled_data, confidence_threshold=0.98):\n",
    "    \"\"\"\n",
    "    Use 2 models, keep intersection where BOTH are 98%+ confident.\n",
    "    \"\"\"\n",
    "    from tqdm.auto import tqdm\n",
    "    \n",
    "    # Pick 2 best models (first 2 from ensemble)\n",
    "    model1, model2 = ensemble_models[0], ensemble_models[1]\n",
    "    \n",
    "    # Trainer args\n",
    "    dummy_args = TrainingArguments(\n",
    "        output_dir=\"../temp\",\n",
    "        per_device_eval_batch_size=128,\n",
    "        dataloader_num_workers=16,\n",
    "        bf16=True,\n",
    "    )\n",
    "    \n",
    "    print(\"Getting predictions from model 1...\")\n",
    "    model1.eval()\n",
    "    trainer1 = Trainer(\n",
    "        model=model1,\n",
    "        args=dummy_args,\n",
    "        data_collator=new_collator,\n",
    "        processing_class=tok,\n",
    "    )\n",
    "    preds1 = trainer1.predict(unlabeled_data)\n",
    "    pred_array1 = preds1.predictions\n",
    "    if pred_array1.ndim == 3:\n",
    "        # Get confidences before argmax\n",
    "        probs1 = torch.softmax(torch.from_numpy(pred_array1), dim=-1).numpy()\n",
    "        conf1 = probs1.max(axis=-1)  # (num_examples, seq_len)\n",
    "        pred_array1 = pred_array1.argmax(-1)\n",
    "    else:\n",
    "        # Already decoded, assume high confidence\n",
    "        conf1 = np.ones_like(pred_array1, dtype=np.float32) * 0.99\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"Getting predictions from model 2...\")\n",
    "    model2.eval()\n",
    "    trainer2 = Trainer(\n",
    "        model=model2,\n",
    "        args=dummy_args,\n",
    "        data_collator=new_collator,\n",
    "        processing_class=tok,\n",
    "    )\n",
    "    preds2 = trainer2.predict(unlabeled_data)\n",
    "    pred_array2 = preds2.predictions\n",
    "    if pred_array2.ndim == 3:\n",
    "        probs2 = torch.softmax(torch.from_numpy(pred_array2), dim=-1).numpy()\n",
    "        conf2 = probs2.max(axis=-1)\n",
    "        pred_array2 = pred_array2.argmax(-1)\n",
    "    else:\n",
    "        conf2 = np.ones_like(pred_array2, dtype=np.float32) * 0.99\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Find intersection where both agree AND both confident\n",
    "    print(\"Finding high-confidence agreement...\")\n",
    "    high_confidence_examples = []\n",
    "    \n",
    "    for example_idx in tqdm(range(len(unlabeled_data))):\n",
    "        example = unlabeled_data[example_idx]\n",
    "        \n",
    "        preds_m1 = pred_array1[example_idx]\n",
    "        preds_m2 = pred_array2[example_idx]\n",
    "        conf_m1 = conf1[example_idx]\n",
    "        conf_m2 = conf2[example_idx]\n",
    "        \n",
    "        agreed_sequence = []\n",
    "        high_conf = True\n",
    "        \n",
    "        for token_idx in range(len(preds_m1)):\n",
    "            # Skip padding\n",
    "            if preds_m1[token_idx] == -100:\n",
    "                continue\n",
    "            \n",
    "            # Both must agree\n",
    "            if preds_m1[token_idx] != preds_m2[token_idx]:\n",
    "                high_conf = False\n",
    "                break\n",
    "            \n",
    "            # Both must be confident\n",
    "            if conf_m1[token_idx] < confidence_threshold or conf_m2[token_idx] < confidence_threshold:\n",
    "                high_conf = False\n",
    "                break\n",
    "            \n",
    "            agreed_sequence.append(int(preds_m1[token_idx]))\n",
    "        \n",
    "        if high_conf and len(agreed_sequence) > 0:\n",
    "            high_confidence_examples.append({\n",
    "                'example': example,\n",
    "                'predicted_labels': agreed_sequence,\n",
    "            })\n",
    "    \n",
    "    return high_confidence_examples\n",
    "\n",
    "\n",
    "# Use 2 models only\n",
    "confident_preds = get_confident_predictions_two_models(\n",
    "    ensemble_models[:2],  # Use first 2 models\n",
    "    tokenised_unlabeled,\n",
    "    confidence_threshold=0.98\n",
    ")\n",
    "\n",
    "print(f\"Found {len(confident_preds)} high-confidence examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88df49b1-b411-4878-8692-70032b6ca9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b28627e-8320-42c8-9a3e-1c646a8c4dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_confident_to_training(confident_preds, tokenised_examples):\n",
    "    \"\"\"Convert high-confidence predictions to training format.\"\"\"\n",
    "    new_training_examples = []\n",
    "    \n",
    "    for conf_pred in confident_preds:\n",
    "        example = conf_pred['example']\n",
    "        pred_labels = conf_pred['predicted_labels']\n",
    "        \n",
    "        # Get original tokens\n",
    "        tokens = example['tokens']\n",
    "        word_ids = example['word_ids']\n",
    "        \n",
    "        # Map back to word-level labels\n",
    "        word_labels = []\n",
    "        prev_wid = None\n",
    "        label_idx = 0\n",
    "        \n",
    "        for wid in word_ids:\n",
    "            if wid is not None and wid != prev_wid:\n",
    "                if label_idx < len(pred_labels):\n",
    "                    word_labels.append(pred_labels[label_idx])\n",
    "                    label_idx += 1\n",
    "                prev_wid = wid\n",
    "        \n",
    "        if len(word_labels) == len(tokens):\n",
    "            new_training_examples.append({\n",
    "                'tokens': tokens,\n",
    "                'ner_tags': word_labels,\n",
    "                'Category': example['category_id']\n",
    "            })\n",
    "    \n",
    "    return new_training_examples\n",
    "\n",
    "\n",
    "# Convert\n",
    "pseudo_labeled = convert_confident_to_training(confident_preds, tokenised_unlabeled)\n",
    "\n",
    "# Combine with original 5K\n",
    "original_examples = rows_to_examples(tagged)\n",
    "combined_training = original_examples + pseudo_labeled\n",
    "\n",
    "print(f\"Original: {len(original_examples)}, Pseudo: {len(pseudo_labeled)}\")\n",
    "print(f\"Total training: {len(combined_training)}\")\n",
    "# Expect: 5K + 5-10K = 10-15K total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47e5fbd1-1cdf-4114-ae3e-5331c74fb6f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8044e12888324686b5a2a33a81654bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model 42 - model_42_expanded\n",
      "============================================================\n",
      "\n",
      "Loading DAPT encoder from ../models/deberta-improved-weak-ner-mk-2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1505' max='1505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1505/1505 22:20, Epoch 35/35]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>13.297400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>12.469500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>10.757600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>8.251400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>5.882900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.311800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>3.624800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.311300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>3.115800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.953400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.899500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.851100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.819600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.782600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.765100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.746400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.718700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.705400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.680200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.641500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.665100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.634800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.622100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.628600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.607100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.595600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.599700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.588300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.564600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.569000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.558900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.547400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.569500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.544600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.532700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.553300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.528600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.531500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>2.525900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.519900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>2.526600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.508100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>2.527600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.521900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>2.505900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.524800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>2.501300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.519700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>2.515200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.501100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.515700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.509500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>2.496700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.498200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>2.513400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.509600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>2.503100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.510000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model 123 - model_123_expanded\n",
      "============================================================\n",
      "\n",
      "Loading DAPT encoder from ../models/deberta-improved-weak-ner-mk-2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1505' max='1505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1505/1505 22:19, Epoch 35/35]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>12.878000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>12.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>10.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>8.108100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>5.779700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>3.585800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>3.116200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.996900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.904400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.871800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.827900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.793000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.752100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.727400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.725200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.671300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.660500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.632900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.610700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.591500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.563500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.563300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.551400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.541000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.534900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.520900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.519600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.508600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.491700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.503400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.492800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.495200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>2.481500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.501100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>2.471500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.478100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>2.467500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.475700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>2.463900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.484400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>2.463000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.474100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>2.489300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.442800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.458100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>2.481500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.459200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>2.468600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.459000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>2.465300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.458600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model 456 - model_456_expanded\n",
      "============================================================\n",
      "\n",
      "Loading DAPT encoder from ../models/deberta-improved-weak-ner-mk-2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1505' max='1505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1505/1505 22:18, Epoch 35/35]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>13.448400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>12.627000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>10.931900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>8.255800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>5.720100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.274900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>3.571900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>3.107600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.917200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.894400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.860700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.805900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.774600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.735700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.718700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.705500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.680800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.678100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.664500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.634000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.629700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.604100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.617900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.595900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.596200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.573500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.581000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.564200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.569800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.565700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.557700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.557400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.527600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.542700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.531400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.535500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>2.531900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.522000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>2.533400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.501700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>2.538600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.509700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>2.535800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.510300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>2.507000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.513400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>2.524600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.521700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.505600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.492900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>2.518700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.501300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>2.520600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.519200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>2.502600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.517100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model 789 - model_789_expanded\n",
      "============================================================\n",
      "\n",
      "Loading DAPT encoder from ../models/deberta-improved-weak-ner-mk-2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1505' max='1505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1505/1505 22:17, Epoch 35/35]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>12.514800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>11.656200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>9.906800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>7.477900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>5.321200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.052200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>3.503400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.256600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>3.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.929700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.883000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.845400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.818800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.764000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.765100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.739700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.707000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.717600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.673700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.660900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.656100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.643000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.632800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.612900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.612200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.600600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.592100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.574900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.566000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.558200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.572400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.539300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.546500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.524500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.534000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.515400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>2.522000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.522700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>2.522700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.517300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>2.516400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.501500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>2.519900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.506800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>2.504900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.506200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>2.510400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.489100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.515700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.501200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>2.503200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.489500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>2.508500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.490400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>2.510100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.508700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model 2024 - model_2024_expanded\n",
      "============================================================\n",
      "\n",
      "Loading DAPT encoder from ../models/deberta-improved-weak-ner-mk-2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1505' max='1505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1505/1505 22:19, Epoch 35/35]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>13.194700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>12.373100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>10.727700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>8.325200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>5.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.271400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>3.583900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.291200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>3.118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.042400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.969900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.873300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.862000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.799100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.760500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.765500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.740800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.745800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.698800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.697600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.673600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.673900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.651500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.632400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.627800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.615200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.623500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.608300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.592300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.596300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.578300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.569500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.578300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.563800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.564100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.540300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.558900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.563500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.562900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>2.521700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.546600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>2.535500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.515400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>2.548500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.522300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>2.539600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.519800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>2.530900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.528500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>2.518600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.523800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.520900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.524300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>2.518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.514500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>2.517100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>2.527200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.514400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create new dataset\n",
    "expanded_ds = Dataset.from_list(combined_training)\n",
    "expanded_tokenised = expanded_ds.map(tok_fn, batched=True, remove_columns=[\"tokens\", \"ner_tags\", \"Category\"])\n",
    "\n",
    "# Retrain 5 models (not 10, to save time)\n",
    "ensemble_seeds_v2 = [42, 123, 456, 789, 2024]\n",
    "\n",
    "for seed in ensemble_seeds_v2:\n",
    "    model_path = train_single_model(\n",
    "        seed, \n",
    "        f\"model_{seed}_expanded\",\n",
    "        expanded_tokenised  # Use expanded data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15ba6ec7-403d-4cb1-8551-16130ed93a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_paths = [f\"../models/deberta-ner-ensemble-seed{42}-final-confidence\", f\"../models/deberta-ner-ensemble-seed{123}-final-confidence\", \n",
    "                  f\"../models/deberta-ner-ensemble-seed{456}-final-confidence\", f\"../models/deberta-ner-ensemble-seed{789}-final-confidence\", f\"../models/deberta-ner-ensemble-seed{2024}-final-confidence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fac297bb-0c85-4430-b1d6-1cfce61a60eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c701d4dbaef34b9080e5e58bb2e7df43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../models/deberta-ner-ensemble-seed42-final-confidence...\n",
      "Loading model from ../models/deberta-ner-ensemble-seed123-final-confidence...\n",
      "Loading model from ../models/deberta-ner-ensemble-seed456-final-confidence...\n",
      "Loading model from ../models/deberta-ner-ensemble-seed789-final-confidence...\n",
      "Loading model from ../models/deberta-ner-ensemble-seed2024-final-confidence...\n",
      "Predicting with model 1/5...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model 2/5...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model 3/5...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model 4/5...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model 5/5...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing majority voting...\n",
      "✓ Ensemble predictions shape: (25000, 49)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ENSEMBLE PREDICTION (Majority Voting)\n",
    "# ============================================================================\n",
    "# ensemble_paths = [f\"../models/deberta-ner-ensemble-seed{42}-final\", f\"../models/deberta-ner-ensemble-seed{123}-final\", f\"../models/deberta-ner-ensemble-seed{456}-final\", f\"../models/deberta-ner-ensemble-seed{789}-final\", f\"../models/deberta-ner-ensemble-seed{2024}-final\"]\n",
    "def load_ensemble_models(model_paths):\n",
    "    \"\"\"Load all trained models.\"\"\"\n",
    "    models = []\n",
    "    \n",
    "    for path in model_paths:\n",
    "        print(f\"Loading model from {path}...\")\n",
    "        \n",
    "        # Let AutoModel handle the loading\n",
    "        from transformers import AutoModelForTokenClassification\n",
    "        \n",
    "        # This won't work directly, so use manual approach:\n",
    "        cfg = AutoConfig.from_pretrained(path)\n",
    "        \n",
    "        # Reinitialize the full model structure\n",
    "        model = CatAwareCRF(\n",
    "            cfg,\n",
    "            num_labels=len(label_list),\n",
    "            allow_mask=allow_mask,\n",
    "            base_model_name=None,\n",
    "            use_dapt=True\n",
    "        )\n",
    "        \n",
    "        # Now load the task-specific layers\n",
    "        from safetensors.torch import load_file\n",
    "        state_dict = load_file(f\"{path}/model.safetensors\")\n",
    "        model.load_state_dict(state_dict)  # Load everything!\n",
    "        # # Load only the task layers (cat_embed, proj, crf)\n",
    "        # task_dict = {k: v for k, v in state_dict.items() \n",
    "        #              if k.startswith(('cat_embed', 'proj', 'crf'))}\n",
    "        # model.load_state_dict(task_dict, strict=False)\n",
    "        \n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    \n",
    "    return models\n",
    "\n",
    "\n",
    "def ensemble_predict(models, tokenised_quiz, trainer_args):\n",
    "    \"\"\"\n",
    "    Get predictions from all models and vote.\n",
    "    Returns: voted predictions (batch_size, seq_len)\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"Predicting with model {i+1}/{len(models)}...\")\n",
    "        \n",
    "        # Create temporary trainer for prediction\n",
    "        temp_trainer = Trainer(\n",
    "            model=model,\n",
    "            args=trainer_args,\n",
    "            data_collator=new_collator,\n",
    "            processing_class=tok,\n",
    "        )\n",
    "        \n",
    "        # Ensure labels are NOT passed (triggers decode path)\n",
    "        pred_output = temp_trainer.predict(tokenised_quiz)\n",
    "        pred_output_array = pred_output.predictions\n",
    "        \n",
    "        # Check shape and handle accordingly\n",
    "        if pred_output_array.ndim == 3:\n",
    "            # Training mode was triggered - logits returned\n",
    "            pred_ids = pred_output_array.argmax(-1)\n",
    "        elif pred_output_array.ndim == 2:\n",
    "            # Inference mode - already decoded IDs\n",
    "            pred_ids = pred_output_array\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected prediction shape: {pred_output_array.shape}\")\n",
    "        \n",
    "        # CRF already decoded, predictions are label IDs\n",
    "        all_predictions.append(pred_ids)\n",
    "        \n",
    "        # Clear memory\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Voting: majority wins\n",
    "    print(\"Performing majority voting...\")\n",
    "    all_predictions = np.array(all_predictions)  # (num_models, batch_size, seq_len)\n",
    "    \n",
    "    voted_predictions = []\n",
    "    for i in range(all_predictions.shape[1]):  # For each example\n",
    "        example_preds = all_predictions[:, i, :]  # (num_models, seq_len)\n",
    "        \n",
    "        # Majority vote per token\n",
    "        voted_seq = []\n",
    "        for j in range(example_preds.shape[1]):  # For each token\n",
    "            token_votes = example_preds[:, j]\n",
    "            \n",
    "            # Ignore -100 (padding/special tokens)\n",
    "            valid_votes = token_votes[token_votes != -100]\n",
    "            \n",
    "            if len(valid_votes) == 0:\n",
    "                voted_seq.append(-100)\n",
    "            else:\n",
    "                # Most common prediction\n",
    "                from collections import Counter\n",
    "                vote_counts = Counter(valid_votes)\n",
    "                majority_vote = vote_counts.most_common(1)[0][0]\n",
    "                # voted_seq.append(majority_vote)\n",
    "                voted_seq.append(int(majority_vote))\n",
    "        \n",
    "        voted_predictions.append(voted_seq)\n",
    "    \n",
    "    # return np.array(voted_predictions)\n",
    "    return np.array(voted_predictions, dtype=np.int64)\n",
    "    \n",
    "# ============================================================================\n",
    "# LOAD QUIZ DATA\n",
    "# ============================================================================\n",
    "\n",
    "quiz = (\n",
    "    pd.read_csv(\"../data/Listing_Titles.tsv\", sep=\"\\t\", \n",
    "                keep_default_na=False, na_values=None)\n",
    "    .query(\"5001 <= `Record Number` <= 30000\")\n",
    ")\n",
    "\n",
    "quiz[\"tokens\"] = quiz[\"Title\"].str.split()\n",
    "quiz_ds = Dataset.from_pandas(\n",
    "    quiz[[\"Record Number\", \"Category\", \"tokens\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "\n",
    "def tok_quiz(batch):\n",
    "    enc = tok(\n",
    "        batch[\"tokens\"],\n",
    "        is_split_into_words=True,\n",
    "        padding=False,\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "    \n",
    "    enc[\"labels\"] = [[-100] * len(ids) for ids in enc[\"input_ids\"]]\n",
    "    enc[\"word_ids\"] = [enc.word_ids(i) for i in range(len(enc[\"input_ids\"]))]\n",
    "    enc[\"category_id\"] = batch[\"Category\"]\n",
    "    enc[\"record_id\"] = batch[\"Record Number\"]\n",
    "    enc[\"tokens\"] = batch[\"tokens\"]\n",
    "    return enc\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(base_model)\n",
    "tokenised_quiz = quiz_ds.map(tok_quiz, batched=True, remove_columns=[])\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ENSEMBLE INFERENCEFl\n",
    "# ============================================================================\n",
    "\n",
    "# Load all ensemble models\n",
    "\n",
    "ensemble_models = load_ensemble_models(ensemble_paths)\n",
    "\n",
    "# Dummy trainer args for prediction\n",
    "dummy_args = TrainingArguments(\n",
    "    output_dir=\"../temp\",\n",
    "    per_device_eval_batch_size=48,\n",
    "    dataloader_num_workers=16,\n",
    "    bf16=True,\n",
    ")\n",
    "\n",
    "# Get ensemble predictions\n",
    "pred_ids = ensemble_predict(ensemble_models, tokenised_quiz, dummy_args)\n",
    "\n",
    "print(f\"✓ Ensemble predictions shape: {pred_ids.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8925faa6-209a-4e5b-96da-8b4116921c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode predictions\n",
    "records = []\n",
    "\n",
    "for i, ex in enumerate(tokenised_quiz):\n",
    "    rec = int(ex[\"record_id\"])\n",
    "    cat = int(ex[\"category_id\"])\n",
    "    words = ex[\"tokens\"]\n",
    "    wids = ex[\"word_ids\"]\n",
    "    labs = [id2label[idx] if idx != -100 else \"O\" for idx in pred_ids[i]]\n",
    "    \n",
    "    # Keep only first sub-word label per word\n",
    "    word_labels = []\n",
    "    prev_wid = None\n",
    "    for wid, lab in zip(wids, labs):\n",
    "        if wid is not None and wid != prev_wid:\n",
    "            word_labels.append((wid, lab))\n",
    "            prev_wid = wid\n",
    "    \n",
    "    # Decode entities correctly\n",
    "    current_tokens = []\n",
    "    current_tag = None\n",
    "    \n",
    "    for wid, label in word_labels:\n",
    "        word = words[wid]\n",
    "        \n",
    "        if label == \"O\":\n",
    "            # Flush any current entity\n",
    "            if current_tokens and current_tag:\n",
    "                records.append((rec, cat, current_tag, \" \".join(current_tokens)))\n",
    "                current_tokens = []\n",
    "                current_tag = None\n",
    "            # Add O token\n",
    "            records.append((rec, cat, \"O\", word))\n",
    "            continue\n",
    "        \n",
    "        prefix, tag = label.split(\"-\", 1)\n",
    "        \n",
    "        # Check if tag is legal for this category\n",
    "        if tag not in allow[cat]:\n",
    "            continue\n",
    "        \n",
    "        if prefix == \"B\":\n",
    "            # NEW entity starts - flush previous\n",
    "            if current_tokens and current_tag:\n",
    "                records.append((rec, cat, current_tag, \" \".join(current_tokens)))\n",
    "            # Start new entity\n",
    "            current_tokens = [word]\n",
    "            current_tag = tag\n",
    "        elif prefix == \"I\":\n",
    "            # Continuation of entity\n",
    "            if tag == current_tag:\n",
    "                current_tokens.append(word)\n",
    "            else:\n",
    "                # I- tag doesn't match current - treat as new entity (model error)\n",
    "                if current_tokens and current_tag:\n",
    "                    records.append((rec, cat, current_tag, \" \".join(current_tokens)))\n",
    "                current_tokens = [word]\n",
    "                current_tag = tag\n",
    "    \n",
    "    # Flush final entity\n",
    "    if current_tokens and current_tag:\n",
    "        records.append((rec, cat, current_tag, \" \".join(current_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "788b7a5b-0ecd-4403-a9e1-cd09e1e1792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out O tags for submission\n",
    "submission = pd.DataFrame(records, columns=[\"Record Number\", \"Category\", \"Tag\", \"Token\"])\n",
    "submission = submission[submission[\"Tag\"] != \"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f28002d-79b9-422c-8364-0ced6deadb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE saving submission, validate categories\n",
    "quiz_categories = quiz.set_index(\"Record Number\")[\"Category\"].to_dict()\n",
    "\n",
    "# Validate each submission row\n",
    "for idx, row in submission.iterrows():\n",
    "    rec_num = row[\"Record Number\"]\n",
    "    expected_cat = quiz_categories.get(rec_num)\n",
    "    if row[\"Category\"] != expected_cat:\n",
    "        print(f\"⚠️ Category mismatch at record {rec_num}!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38239d99-fe9b-45ad-9c73-c8c2decb0f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "submission.to_csv(\n",
    "    \"../results/weak-nerMK2-smooth0-01-ensemble-confidence.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=False,\n",
    "    index=False,\n",
    "    encoding=\"utf-8\",\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    escapechar=\"\\\\\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM-TESTING)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
